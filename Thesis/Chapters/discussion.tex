\chapter{Discussion}\label{chap:discussion}
The goal of this work was to design and implement an adversarial attack that was both efficient and evasive. Efficiency is measured as the $L_2$-distance between the original image and the resulting adversarial example. Evasiveness is determined by the number of detections triggered by a stateful defense mechanism \cite{chen_stateful_2019}. As shown throughout this work, the goals are conflicting. Lowering the distance to the original image usually implies more detections as a certain region in search space is queried more.\\

The key idea to avoid detection was to exploit the assumption made by the stateful defense mechanism. The scheme assumes that there is no cooperation between attackers and that all submitted queries from one user could be traced back to this user. By distributing the submission of queries over multiple nodes, and thus multiple accounts, the defensive mechanism can't trace back the origin of the queries to a single user.\\

The distribution of the query submission lowers the number of detections without altering the efficiency of the attack. It could be naively assumed that distributing the submission over $N$ nodes would reduce the number of detections by a factor of~$N$. This is not the case as has been shown in section \ref{sec:distribution}. This effect can be explained intuitively using the following example: assume that identical queries are being submitted to a model and that this model uses a stateful defensive scheme with $k$ equal to 50. This would cause every 51$^{\text{st}}$ query to be flagged since a buffer of 50 queries should be constructed first. If this query is submitted 102 times to a node, then two detections will be flagged. If the submission is distributed over two nodes, then every node will receive 51 queries, causing one detection to occur per node. This results in a total of two detections. The real improvement of the distribution lies in the fact that the queries submitted to a single node are further apart in the attack process. The attack is able to move to different areas of the search space during this time, causing the queries to be less similar. A promising path to investigate is the development of better distribution schemes as the suggested schemes in this work were not very effective.\\

The best method to avoid detection is to submit queries that are as dissimilar as possible. Several techniques have been explored in this regard. The first idea was specific to the \gls{bba}. By selecting multiple starting points for the attack, it was possible to improve both the efficiency and evasiveness. By changing the number of starting positions, it was also possible to make a trade-off between efficiency and evasiveness depending on the costs associated with submitting a query or getting detected.\\

The second and third techniques are essentially applicable to all adversarial attacks. The second technique consisted of inserting noise queries that did not contribute to the attack itself. This proved to be too costly in terms of efficiency for a small gain in evasiveness. However, there is still a lot of potential in this idea. Future work could implement some more sophisticated insertion schemes with better hyperparameter choices. It should be possible to perform any attack using a single account with a near-perfect insertion scheme. This would be beneficial if the cost associated with creating a new account is very high.\\

The third technique was to run attacks concurrently and interleave the query submission of this group of attacks. This causes submitted queries to be more spread out similar to the noise insertion. The additional advantage of this technique over noise insertion is that the submitted queries are no longer unpurposed. Every query contributes to an attack of the group. The next steps could be to optimize the selection of the attacks in the group since attacks with the same starting or target label tend to help the defense to trigger more detections. A better distribution scheme, specifically designed for this technique, could also be an improvement.\\

The final algorithm was less efficient than the current state-of-the-art \gls{hsja} \cite{hsja}. However, the attack proposed in this work was more evasive. This makes the algorithm a viable candidate for adversarial attacks, especially when evasion is the primary goal. There are most definitely improvements possible by optimizing the hyperparameters of the attack. These parameters could again be tweaked depending on the needs of the attacker. It should also be noted that the parameters of \gls{hsja} are not optimized for the distributed setting. Tuning these parameters using an optimization framework such as \gls{pso} or Optuna \cite{optuna} might make the attack more evasive in this setting.\\

Some other ideas were considered during the creation of this work, but have not been explored further. These ideas could be promising starting points for further research. The first idea was to have a dynamic number of particles in the \gls{pso} swarm. As shown in Figure \ref{fig:detections_bba_vs_pso_bba}, detections occur more frequently by the end of the attack process. This is due to the particles converging to a single region in search space, causing the resulting queries to be more similar. It could be beneficial to reduce the number of particles if this is the case. Depending on the hyperparameter values of the attack, this might cause fewer detections if the movements of a particle are large enough. It could also cause a gain in efficiency since more queries can be assigned to a single particle, giving the particle more time to find a good adversarial position.\\

A second idea was to use the \gls{pso}-\gls{bba} algorithm as initialization for another, more efficient attack similar to the hybridization approach taken in \glspl{ea}. Efficient attacks such as \gls{hsja} tend to trigger more detections since they use a lot of queries to find the best direction to move towards. This already causes a lot of detection from the start of the process. By assigning part of the query budget to the \gls{pso}-\gls{bba} algorithm, adversarial examples can be generated without triggering many detections. These examples can be used as starting points for a more efficient attack, reducing the number of attacks flagged before arriving at this point.\\

Instead of optimizing the attack proposed in this work, future research might focus on a defensive scheme able to detect this attack. Different approaches can be taken to achieve this goal. A first approach is to relax the assumption of the stateful detection scheme that there is no cooperation possible between different users. Instead of using a buffer per user, a single larger buffer can be used for the entire model. All queries submitted to the model will be added to this buffer. This allows for the detection of attacks where the query submission is spread out over multiple accounts. However, it might also cause a lot of false positive detections.\\ 

A second approach could be to link buffers that might belong to the same attack together. This could potentially be done by calculating the average image inside the buffer and using a similarity encoder to find similar buffers. This approach has the advantage over the first approach, that benign users' queries are not necessarily compared to all other queries. This should cause a lower false positive detection rate, albeit still higher than the original stateful defensive scheme.\\

A third approach is to use a similarity encoder directly for buffers. This allows for another way of linking buffers together based on similarity and could therefore serve as an alternative to the second approach. It could also be used to detect attacks in itself. By training the similarity encoder with benign and adversarial buffers, buffers could be classified as adversarial based on the distance to other adversarial buffers. This would require training buffers that are attack specific. Different parameter values might change some aspects of the buffer, meaning that training data has to be available for different parameter settings. It might therefore be a very time and resource-consuming idea, but there is potential here.\\% Buffer of buffers, similarity between buffers (average image), all queries in one large buffer