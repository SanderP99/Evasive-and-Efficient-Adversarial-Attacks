\chapter{Conclusion}\label{chap:conclusion}
This chapter aims to conclude this work by answering the research questions posed in section \ref{sec:approach}:\\

\textbf{What are the (dis)advantages of using \gls{pso} in relation to vanilla adversarial attacks?}\\
\gls{pso} is an optimization framework where particles move through search space where every position is mapped to a fitness value. The framework tries to guide the particles to regions with good fitness values. \gls{pso} requires no notion of the underlying problem it is trying to solve. It only requires a fitness function to be defined for the entire search space. This allows for the optimization of problems that could not be solved analytically.\\

Adversarial attacks can be seen as such a problem. It requires finding a position (or image) in search space that is as close as possible to an original image, while receiving a different classification than the original image by the model under attack. Depending on the information available about the model, white-box and black-box attacks can be distinguished. White-box attacks have complete knowledge about the model. This knowledge includes the architecture, parameters, weights and gradients. Especially the gradients are very useful in order to optimize the adversarial examples generated by an attack. Methods such as \gls{fgsm} \cite{FGSM} use these gradients to quickly improve the adversarial position. Whenever this information is available, \gls{pso} is not strong candidate for the optimization process as it does not use this information.\\

However, most real models operate without providing this information to its users. Black-box attacks such as \gls{bba} \cite{brunner_guessing_2019} and \gls{hsja} \cite{hsja} are able to work around this lack of knowledge. \gls{hsja} in particular is able to closely match the performance of some white-box attacks, but it requires more queries in doing so. These extra queries allow for more detections by a stateful defense \cite{chen_stateful_2019}, since successive queries tend to be similar in appearance.\\

\gls{pso} is less prone to detections due to its multiple starting points. The queries submitted to the model originate from different regions of the search space, making them less similar to each other. This is one of the main advantages of \gls{pso} as was discussed in section \ref{sec:combining_pso_bba}. It was also shown that \gls{pso} could lead to a more efficient algorithm. Vanilla adversarial attacks might terminate the attack process in local optima. By starting from multiple positions, the probability of ending in a local optimum is lowered, which in turn explains the higher efficiency.\\

The main disadvantage of \gls{pso} is the number of hyperparameters present in the framework. Incorrectly tuning the values of these parameters can lead adversarial attacks that are less efficient than their vanilla counterparts. The tuning process is also very time and energy consuming. The optimal values are dependent on the settings of the defensive scheme. This information is not available in a black-box setting. The combination of these factors causes \gls{pso} to be tricky to get right, but promising when done right.\\ 

	 
\textbf{How can \gls{pso} be combined with state of the art adversarial attacks?}\\
This work proposes the \gls{pso}-\gls{bba} attack, a combination of \gls{pso} and \gls{bba}. The vanilla \gls{bba} iteratively updates the position of an image in search space in order to move closer to the original image. The \gls{pso} framework has particles moving through search space in order to find positions with a good fitness value. Both \gls{pso} and \gls{bba} guide candidate solutions trough search space which makes them straightforward to combine. The proposed adversarial attack is more efficient and evasive than vanilla \gls{bba}.\\

Combining \gls{pso} and \gls{hsja} is less straightforward. As discussed in chapter \ref{chap:discussion}, \gls{pso} could be used to optimize the hyperparameters of \gls{hsja} with evasiveness as the primary goal. \gls{pso} could also be used as an initialization for other adversarial attacks. The less efficient \gls{pso}-\gls{bba} algorithm triggers fewer detections compared to \gls{hsja}. The first iterations of \gls{hsja} could be replaced by \gls{pso}-\gls{bba} in order to obtain better adversarial positions to start \gls{hsja} from.\\ 
	
\textbf{What are the (dis)advantages of distributing an adversarial attack?}\\
The main advantage of distributing an adversarial attack is evasiveness. By distributing the query submission over multiple nodes, successive queries submitted to the same node are further apart in the attack process. These queries are therefore less similar and trigger less detection by a stateful defensive mechanism. Section \ref{sec:distribution} discussed the results of distributing \gls{pso}-\gls{bba} over multiple nodes. \\

This approach requires that the attacker has access to a large number of accounts and nodes. The nodes are only used to submit queries, making it that they do not require much computational power. Creating a new account might be a time consuming process, causing the attacker to create  accounts in bulk. The attacker does not know beforehand how many accounts are needed in order to perform a successful attack. This may cause the attacker to create spare accounts that can be used when another account is banned. However, it can be argued that these spare accounts can already be used from the beginning of the attack in order to be even more evasive. Using this logic, all accounts should be utilized from the beginning of the attack. Therefore, every detection means that the attacker has to create a new account or that the number of accounts is reduced by one.\\  

\textbf{How can adversarial attacks be made more evasive?}\\
As mentioned in the answer of the previous research question, distributing the query submission can make an attack more evasive. As shown in Figure \ref{fig:detections_nodes}, when the number of nodes is high enough, the attack can be performed without triggering any detections. Several distribution schemes have been proposed, but these proved to be very similar in performance.\\

It is not always possible to increase the number of nodes. For this reason, other techniques that increase the evasiveness of an attack have been proposed. The \gls{pso}-\gls{bba} algorithm uses multiple starting positions to increase the evasiveness. However, this technique is not applicable to all adversarial attacks.\\

Another approach to increase the evasiveness of an attack without increasing the number of nodes is to insert noise queries in order to flush the buffer of the defensive scheme. Different types of noise queries and different insertion schemes were tested, but they caused the attack to be too inefficient for the gain in evasiveness. Instead of inserting noise queries, purposeful queries could also be inserted. This is done by running multiple attacks concurrently and interleaving the query submission of all these attacks. As shown in Figure \ref{fig:detections_combinations}, by increasing the number of concurrent attacks, the average number of detections drop. This approach is extremely useful if the attacker is interested in multiple adversarial examples.\\ 