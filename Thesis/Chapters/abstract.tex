\begin{abstract}
% Adversarial examples
% Defense
% New attack
% More evasive
Adversarial attacks craft small perturbations that can be added to inputs, so that they are classified incorrectly by a classifier. Current defensive schemes try to flag these attacks based on the similarity between successive submitted queries. This work aims to implement a new adversarial attack that is able to bypass this detection mechanism. This attack is called PSO-BBA after the two constituent algorithms Particle Swarm Optimization and Biased Boundary Attack \cite{brunner_guessing_2019}. Other improvements, such as distributing the query submission over multiple nodes or grouping attacks together have been explored as well. The final attack is more evasive than current state-of-the-art attacks, but is slightly less efficient. The attacker has to make a trade-off depending on the primary goal of the attack.
\end{abstract}